---
title: "vignette"
output:
  html_document: default
  pdf_document: default
date: '2023-12-05'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Binary Classification Vignette

For the purpose of this vignette, we will use data from the National Institute of Diabetes and Digestive Kidney Disease.

Activity: Creating different models using binary classification algorithms 

We will fit multiple models and compute basic classification accuracy measures in order to compare the models and see which one should be the final model chosen. 

Prerequisites
First we will start the setup by loading the required packages and data.
```{r}
# load packages
library(readr)
library(vip)
library(naniar)
library(tidymodels)
library(ISLR)
library(ISLR2)
library(tidyverse)
library(glmnet)
library(modeldata)
library(ggthemes)
library(janitor)
library(kableExtra)
library(yardstick)
library(kknn)
library(corrplot)
library(themis)
library(dplyr)
library(ggplot2)
library(scales)
library(rpart.plot)
library(discrim)
library(klaR)
library(plotly)
library(xgboost)
library(recipes)
library(ROSE)
library(randomForest)
library(reticulate)
tidymodels_prefer()

# read data
db <- read_csv("data/diabetes.csv")

```


```{r}
db <- read_csv("data/diabetes.csv")
#bank_df$Exited_num <- as.numeric(bank_df$Exited) # Convert Exited to numeric variable
diabetes_numeric <- db %>% 
  select_if(is.numeric) # Select only numeric columns
cor_matrix <- cor(diabetes_numeric) # Compute correlation matrix
```

```{r}
# covert survived and pclass into factors
diabetes_numeric$Outcome <- as.factor(diabetes_numeric$Outcome)
# sort the data frame by survived, so the yes will be on top
db_sort <- db%>% arrange(desc(Outcome))
```

Data Partitioning
When data partitioning, we split the data where the training set is used to train the model and the test set is used to evaluate the performance of the model. Partitions are computed at random. 

First we will do cross-validation and data splitting.  
We then partition the diabetes data into training and test sets.
```{r}
set.seed(3435)
db_split <- initial_split(db, prop = 0.80,
                               strata = "Outcome")
db_train <- training(db_split)
db_test <- testing(db_split)
db_fold <- vfold_cv(db_train,v=4)

# Data splitting
db$Outcome <- as.factor(db$Outcome)
set.seed(3435)
db_split <- initial_split(db, prop = 0.80, strata = "Outcome")
db_train <- training(db_split)
db_test <- testing(db_split)
db_fold <- vfold_cv(db_train, v = 6)
```

We will use the package recipes for the Logistic Regression, K-Nearest Neighbors, and Boosted Tree models. We will also use the tune_grid() function to do the hyperparameter tuning for these models as well. 

The main purpose of a recipe is to define a consistent and reproducible set of data preprocessing steps. 

Here we will use the step_dummy() and prep() functions to set up the training model. 
The step_dummy() function is used to convert all nominal variables into dummy variables. The step_normalize() function is used to scale all variables to have a mean of zero and standard deviation of one. 

The prep() function is then used to prepare the recipe object, and bake() is used to apply the recipe to the training set. Finally, the group_by() and summarise() functions are used to count the number of instances of each value of the Outcome variable in the training set.
```{r}

# Recipe without step_upsample
db_recipe <- recipe(Outcome ~ ., data = db_train) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_predictors())

# Prepare the recipe
prep(db_recipe)%>% bake(new_data = db_train) %>% 
  group_by(Outcome) %>% 
  summarise(count = n())

```

Binary Classification Algorithm #1 
Logistic Regression

We will use the logistic_reg() function to generate the specification of the logistic regression model before fitting.
```{r}
db_train$Outcome <- factor(db_train$Outcome)

# Logistic regression
log_reg <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

db_log_wflow <- workflow() %>% 
  add_model(log_reg) %>% 
  add_recipe(db_recipe)

# Tune the model
db_tune_reg <- tune_grid(
  object = db_log_wflow, 
  resamples = db_fold
)

```


Logistic Model Fitting
```{r}
# Fit the model
log_fit <- fit(db_log_wflow, db_train)
```


```{r}
library(pROC)

# Extract predictions
log_preds <- augment(log_fit, new_data = db_train)

# Calculate ROC AUC directly using pROC
roc_curve <- roc(log_preds$Outcome, log_preds$.pred_0)
roc_auc_value <- auc(roc_curve)
print(roc_auc_value)

# Confusion Matrix
conf_matrix <- log_preds %>%
  conf_mat(truth = Outcome, estimate = .pred_class)

# Plot Confusion Matrix
conf_matrix %>% autoplot(type = 'heatmap') +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

# Show best tuning parameters
show_best(db_tune_reg, n = 1)

```


Accuracy Measures
```{r}
library(pROC)

# Extract predictions
log_preds <- augment(log_fit, new_data = db_train)

log_predictions <- augment(log_fit, new_data = db_test)
log_accuracy <- accuracy(log_predictions, truth = Outcome, estimate = .pred_class)
log_conf_matrix <- conf_mat(log_predictions, truth = Outcome, estimate = .pred_class)
```


We will then use the predictions and the observed classes to create a Confusion Matrix table.
```{r}
library(pROC)

# Calculate ROC AUC directly using pROC
roc_curve <- roc(log_preds$Outcome, log_preds$.pred_0)
roc_auc_value <- auc(roc_curve)
print(roc_auc_value)

# Confusion Matrix
conf_matrix <- log_preds %>%
  conf_mat(truth = Outcome, estimate = .pred_class)

# Plot Confusion Matrix
conf_matrix %>% autoplot(type = 'heatmap') +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

# Show best tuning parameters
show_best(db_tune_reg, n = 1)

```



Binary Classification Algorithm #2
K-Nearest Neighbors

We will use the nearest_neighbor() function to generate the specification of the K-Nearest Neighbors model.
```{r}
# Recipe without step_upsample
db_recipe <- recipe(Outcome ~ ., data = db_train) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_predictors())

# Prepare the recipe
prep(db_recipe)%>% bake(new_data = db_train) %>% 
  group_by(Outcome) %>% 
  summarise(count = n())

 
# Define the k-NN model
knn_model <- nearest_neighbor(neighbors = tune()) %>% 
  set_engine("kknn") %>% 
  set_mode("classification")

# Create a workflow with the recipe and model
db_knn_wflow <- workflow() %>% 
  add_recipe(db_recipe) %>%  # Include the recipe
  add_model(knn_model)      # Include the model

# Grid for tuning
neighbors_grid <- grid_regular(neighbors(range = c(1, 10)), levels = 10)

# Tune the model
db_tune_knn <- tune_grid(
  object = db_knn_wflow, 
  resamples = db_fold, 
  grid = neighbors_grid
)

# Select the best model
best_knn_db <- select_best(
  db_tune_knn,
  metric = "roc_auc",
  neighbors
)

```


We will then use the predictions and observed classes to create a Confusion Matrix table.
```{r}
library(pROC)

best_knn_wf <- finalize_workflow(db_knn_wflow, best_knn_db)
knn_fit <- fit(best_knn_wf, data = db_train)

# Extract predictions
knn_preds <- augment(knn_fit, new_data = db_train)

# Calculate ROC AUC directly using pROC
roc_curve <- roc(knn_preds$Outcome, knn_preds$.pred_0)
roc_auc_value <- auc(roc_curve)
print(roc_auc_value)

# Confusion Matrix
conf_matrix <- knn_preds %>%
  conf_mat(truth = Outcome, estimate = .pred_class)

# Plot Confusion Matrix
conf_matrix %>% autoplot(type = 'heatmap') +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

autoplot(db_tune_knn) + theme_minimal()
```


Binary Classification Algorithm #3
Boosted Tree Model
```{r}
bt_class_spec <- boost_tree(mtry = tune(), 
                           trees = tune(), 
                           learn_rate = tune()) %>%
  set_engine("xgboost") %>% 
  set_mode("classification")

bt_class_wf <- workflow() %>% 
  add_model(bt_class_spec) %>% 
  add_recipe(db_recipe)
```

```{r}
bt_grid <- grid_regular(mtry(range = c(1, 6)), 
                        trees(range = c(200, 600)),
                        learn_rate(range = c(-10, -1)),
                        levels = 5)
bt_grid
```

```{r eval=FALSE}
tune_bt_class <- tune_grid(
  bt_class_wf,
  resamples = db_fold,
  grid = bt_grid
)
save(tune_bt_class, file = "tune_bt_class.rda")
```

```{r}
load("tune_bt_class.rda")
autoplot(tune_bt_class) + theme_minimal()
```

```{r}
show_best(tune_bt_class, n = 1)
```

```{r}
best_bt_class <- select_best(tune_bt_class)
```

```{r}
bt_mode_fit <- finalize_workflow(bt_class_wf, best_bt_class)
bt_mode_fit <- fit(bt_mode_fit, db_train)

bt_mode_fit %>% extract_fit_parsnip() %>% 
  vip() +
  theme_minimal()

```

Compute the accuracy measures and create a confusion matrix 
```{r}
bt_predictions <- augment(bt_mode_fit, new_data = db_test)
bt_roc_curve <- roc(bt_predictions$Outcome, bt_predictions$.pred_0)
bt_auc_value <- auc(bt_roc_curve)
bt_conf_matrix <- conf_mat(bt_predictions, truth = Outcome, estimate = .pred_class)

print(paste("Boosted Trees AUC:", bt_auc_value))
print("Boosted Trees Confusion Matrix:")
print(bt_conf_matrix)
```


Next we will use Python to create the models for the Random Forest, Gradient Boosting Decision Trees, and XGBoost, while also creating models for the algorithms already used above.

In order to run python code blocks in R we will use the package called reticulate.
```{r}

# Load the reticulate library
library(reticulate)

# Create a new Conda environment named "myenv" with Python 3.12
conda_create("myenv", python_version = "3.12")

# Activate the Conda environment
use_condaenv("myenv", conda = "auto")

# Verify that the correct Python version is being used
#py_config()

# Install pandas in the Conda environment
reticulate::conda_install(envname = "myenv", packages = c("pandas"))

# Check if pandas is now available
reticulate::py_module_available("pandas")

```


Prequisites
Copy and paste these lines below on Python 
# Load packages
```{python}
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# Load the dataset
db = pd.read_csv("../../data/diabetes.csv")
```


We will also process the data so that there are no missing values to ensure that the data is suitable fo model training. 
```{python}
# Remove rows where any column except 'Pregnancies' or 'Outcome' is 0
cols_to_check = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']
db_filtered = db[(db[cols_to_check] != 0).all(axis=1)]
```


Next we will label and separate the 8 medical predictors and the response variable Outcome.
```{python}
# Separate features and target variable
X = db_filtered.drop('Outcome', axis=1)
y = db_filtered['Outcome']
```



We will then do data partitioning and split the data into training and testing sets. 
```{python}
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
```

Now we can train the models using the functions
RandomForestClassifier()
GradientBoostingClassifier()
XGBClassifier()


```{python}
# Function to compute metrics and plot ROC curve
def compute_metrics_and_plot(model, X_test, y_test, name, filename):
    print(f"\n{name} Metrics:")
    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)
    precision = precision_score(y_test, predictions)
    recall = recall_score(y_test, predictions)
    f1 = f1_score(y_test, predictions)
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-score: {f1:.4f}")   
    # Compute ROC curve and ROC area for each class
    y_scores = model.predict_proba(X_test)[:, 1]  # Get the predicted probabilities
    fpr, tpr, _ = roc_curve(y_test, y_scores)
    auc = roc_auc_score(y_test, y_scores)
    
    # Plot ROC curve
    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc)
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'ROC of {name}')
    plt.legend(loc="lower right")
    plt.savefig(f"../../img/{filename}-default")

```



First we will train the models with the default hyperparameters
```{python}
# Train Random Forest Classifier
rf_model = RandomForestClassifier(random_state=0)
rf_model.fit(X_train, y_train)
compute_metrics_and_plot(rf_model, X_test, y_test, "Random Forest","RanF")

# Train Gradient Boosting Decision Trees (GBDT)
gbdt_model = GradientBoostingClassifier(random_state=0)
gbdt_model.fit(X_train, y_train)
compute_metrics_and_plot(gbdt_model, X_test, y_test, "Gradient Boosted Trees","GBDT")


# Train XGBoost Classifier
xgb_model = XGBClassifier(random_state=0,learning_rate=0.3)
xgb_model.fit(X_train, y_train)
compute_metrics_and_plot(xgb_model, X_test, y_test, "XGBoost","XGB")

```


We will also train models using the 5-fold Cross Validation to allow 
```{python}
# Train Logistic Regression Classifier
lr_model = LogisticRegression(random_state=0, max_iter=1000)
cv_scores = cross_val_score(lr_model, X, y, cv=5, scoring='accuracy')
print(f"Logistic Regression 5-Fold CV Accuracies:", cv_scores)
print("Mean Accuracy:", cv_scores.mean(),'\n')

# Train Random Forest Classifier
rf_model = RandomForestClassifier(random_state=0)
cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy')
print(f"Random Forest 5-Fold CV Accuracies:", cv_scores)
print("Mean Accuracy:", cv_scores.mean(),'\n')

# Train Gradient Boosting Decision Trees (GBDT)
gbdt_model = GradientBoostingClassifier(random_state=0)
cv_scores = cross_val_score(lr_model, X, y, cv=5, scoring='accuracy')
print(f"GBDT 5-Fold CV Accuracies:", cv_scores)
print("Mean Accuracy:", cv_scores.mean(),'\n')

# Train K-Nearest Neighbors (KNN)
knn_model = KNeighborsClassifier()
cv_scores = cross_val_score(knn_model, X, y, cv=5, scoring='accuracy')
print(f"KNN 5-Fold CV Accuracies:", cv_scores)
print("Mean Accuracy:", cv_scores.mean(),'\n')

# Train XGBoost Classifier
xgb_model = XGBClassifier(random_state=0)
cv_scores = cross_val_score(xgb_model, X, y, cv=5, scoring='accuracy')
print(f"XGBoost 5-Fold CV Accuracies:", cv_scores)
print("Mean Accuracy:", cv_scores.mean(),'\n')

```





