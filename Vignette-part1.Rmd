---
title: "Vignette"
output:
  pdf_document: default
  html_document: default
date: '2023-12-05'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Binary Classification Vignette

For the purpose of this vignette, we will use data from the National Institute of Diabetes and Digestive Kidney Disease.

Activity: Creating different models using binary classification algorithms 

We will fit multiple models and compute basic classification accuracy measures in order to compare the models and see which one should be the final model chosen. 

Prerequisites
First we will start the setup by loading the required packages and data.
```{r}
# load packages
library(readr)
library(vip)
library(naniar)
library(tidymodels)
library(ISLR)
library(ISLR2)
library(tidyverse)
library(glmnet)
library(modeldata)
library(ggthemes)
library(janitor)
library(kableExtra)
library(yardstick)
library(kknn)
library(corrplot)
library(themis)
library(dplyr)
library(ggplot2)
library(scales)
library(rpart.plot)
library(discrim)
library(klaR)
library(plotly)
library(xgboost)
library(recipes)
library(ROSE)
library(randomForest)
library(reticulate)
tidymodels_prefer()

# read data
db <- read_csv("data/diabetes.csv")

```


```{r}
db <- read_csv("data/diabetes.csv")
#bank_df$Exited_num <- as.numeric(bank_df$Exited) # Convert Exited to numeric variable
diabetes_numeric <- db %>% 
  select_if(is.numeric) # Select only numeric columns
cor_matrix <- cor(diabetes_numeric) # Compute correlation matrix
```

```{r}
# covert survived and pclass into factors
diabetes_numeric$Outcome <- as.factor(diabetes_numeric$Outcome)
# sort the data frame by survived, so the yes will be on top
db_sort <- db%>% arrange(desc(Outcome))
```

Data Partitioning
When data partitioning, we split the data where the training set is used to train the model and the test set is used to evaluate the performance of the model. Partitions are computed at random. 

First we will do cross-validation and data splitting.  
We then partition the diabetes data into training and test sets.
```{r}
set.seed(3435)
db_split <- initial_split(db, prop = 0.80,
                               strata = "Outcome")
db_train <- training(db_split)
db_test <- testing(db_split)
db_fold <- vfold_cv(db_train,v=4)

# Data splitting
db$Outcome <- as.factor(db$Outcome)
set.seed(3435)
db_split <- initial_split(db, prop = 0.80, strata = "Outcome")
db_train <- training(db_split)
db_test <- testing(db_split)
db_fold <- vfold_cv(db_train, v = 6)
```

# Recipe...
```{r}

# Recipe without step_upsample
db_recipe <- recipe(Outcome ~ ., data = db_train) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_predictors())

# Prepare the recipe
prep(db_recipe)%>% bake(new_data = db_train) %>% 
  group_by(Outcome) %>% 
  summarise(count = n())

```

Binary Classification Algorithm #1 
Logistic Regression

```{r}
db_train$Outcome <- factor(db_train$Outcome)

# Logistic regression
log_reg <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

db_log_wflow <- workflow() %>% 
  add_model(log_reg) %>% 
  add_recipe(db_recipe)

# Tune the model
db_tune_reg <- tune_grid(
  object = db_log_wflow, 
  resamples = db_fold
)

```


Logistic Model Fitting
```{r}
# Fit the model
log_fit <- fit(db_log_wflow, db_train)
```


```{r}
library(pROC)

# Extract predictions
log_preds <- augment(log_fit, new_data = db_train)

# Calculate ROC AUC directly using pROC
roc_curve <- roc(log_preds$Outcome, log_preds$.pred_0)
roc_auc_value <- auc(roc_curve)
print(roc_auc_value)

# Confusion Matrix
conf_matrix <- log_preds %>%
  conf_mat(truth = Outcome, estimate = .pred_class)

# Plot Confusion Matrix
conf_matrix %>% autoplot(type = 'heatmap') +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

# Show best tuning parameters
show_best(db_tune_reg, n = 1)

```


Accuracy Measures
```{r}
library(pROC)

# Extract predictions
log_preds <- augment(log_fit, new_data = db_train)

log_predictions <- augment(log_fit, new_data = db_test)
log_accuracy <- accuracy(log_predictions, truth = Outcome, estimate = .pred_class)
log_conf_matrix <- conf_mat(log_predictions, truth = Outcome, estimate = .pred_class)
```


We will then use the predictions and the observed classes to create a Confusion Matrix table.
```{r}
library(pROC)

# Calculate ROC AUC directly using pROC
roc_curve <- roc(log_preds$Outcome, log_preds$.pred_0)
roc_auc_value <- auc(roc_curve)
print(roc_auc_value)

# Confusion Matrix
conf_matrix <- log_preds %>%
  conf_mat(truth = Outcome, estimate = .pred_class)

# Plot Confusion Matrix
conf_matrix %>% autoplot(type = 'heatmap') +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

# Show best tuning parameters
show_best(db_tune_reg, n = 1)

```



Binary Classification Algorithm #2
K-Nearest Neighbors

```{r}
# Recipe without step_upsample
db_recipe <- recipe(Outcome ~ ., data = db_train) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_predictors())

# Prepare the recipe
prep(db_recipe)%>% bake(new_data = db_train) %>% 
  group_by(Outcome) %>% 
  summarise(count = n())

 
# Define the k-NN model
knn_model <- nearest_neighbor(neighbors = tune()) %>% 
  set_engine("kknn") %>% 
  set_mode("classification")

# Create a workflow with the recipe and model
db_knn_wflow <- workflow() %>% 
  add_recipe(db_recipe) %>%  # Include the recipe
  add_model(knn_model)      # Include the model

# Grid for tuning
neighbors_grid <- grid_regular(neighbors(range = c(1, 10)), levels = 10)

# Tune the model
db_tune_knn <- tune_grid(
  object = db_knn_wflow, 
  resamples = db_fold, 
  grid = neighbors_grid
)

# Select the best model
best_knn_db <- select_best(
  db_tune_knn,
  metric = "roc_auc",
  neighbors
)

```


We will then use the predictions and observed classes to create a Confusion Matrix table.
```{r}
library(pROC)

best_knn_wf <- finalize_workflow(db_knn_wflow, best_knn_db)
knn_fit <- fit(best_knn_wf, data = db_train)

# Extract predictions
knn_preds <- augment(knn_fit, new_data = db_train)

# Calculate ROC AUC directly using pROC
roc_curve <- roc(knn_preds$Outcome, knn_preds$.pred_0)
roc_auc_value <- auc(roc_curve)
print(roc_auc_value)

# Confusion Matrix
conf_matrix <- knn_preds %>%
  conf_mat(truth = Outcome, estimate = .pred_class)

# Plot Confusion Matrix
conf_matrix %>% autoplot(type = 'heatmap') +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

autoplot(db_tune_knn) + theme_minimal()
```


Binary Classification Algorithm #3
Boosted Tree Model
```{r}
bt_class_spec <- boost_tree(mtry = tune(), 
                           trees = tune(), 
                           learn_rate = tune()) %>%
  set_engine("xgboost") %>% 
  set_mode("classification")

bt_class_wf <- workflow() %>% 
  add_model(bt_class_spec) %>% 
  add_recipe(db_recipe)
```

```{r}
bt_grid <- grid_regular(mtry(range = c(1, 6)), 
                        trees(range = c(200, 600)),
                        learn_rate(range = c(-10, -1)),
                        levels = 5)
bt_grid
```

```{r eval=FALSE}
tune_bt_class <- tune_grid(
  bt_class_wf,
  resamples = db_fold,
  grid = bt_grid
)
save(tune_bt_class, file = "tune_bt_class.rda")
```

```{r}
load("tune_bt_class.rda")
autoplot(tune_bt_class) + theme_minimal()
```

```{r}
show_best(tune_bt_class, n = 1)
```

```{r}
best_bt_class <- select_best(tune_bt_class)
```

```{r}
bt_mode_fit <- finalize_workflow(bt_class_wf, best_bt_class)
bt_mode_fit <- fit(bt_mode_fit, db_train)

bt_mode_fit %>% extract_fit_parsnip() %>% 
  vip() +
  theme_minimal()

```

Compute the accuracy measures and create a confusion matrix 
```{r}
bt_predictions <- augment(bt_mode_fit, new_data = db_test)
bt_roc_curve <- roc(bt_predictions$Outcome, bt_predictions$.pred_0)
bt_auc_value <- auc(bt_roc_curve)
bt_conf_matrix <- conf_mat(bt_predictions, truth = Outcome, estimate = .pred_class)

print(paste("Boosted Trees AUC:", bt_auc_value))
print("Boosted Trees Confusion Matrix:")
print(bt_conf_matrix)
```