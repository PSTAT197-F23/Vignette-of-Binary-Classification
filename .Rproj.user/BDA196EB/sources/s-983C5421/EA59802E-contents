---
title: "197final project"
output: html_document
---

diabetes
```{r}
# Suppress warning messages
suppressWarnings({
library(readr)
library(pROC)
library(vip)
library(naniar)
library(tidymodels)
library(ISLR)
library(ISLR2)
library(tidyverse)
library(glmnet)
library(modeldata)
library(ggthemes)
library(janitor)
library(kableExtra)
library(yardstick)
library(kknn)
library(corrplot)
library(themis)
library(dplyr)
library(ggplot2)
library(scales)
library(rpart.plot)
library(discrim)
library(klaR)
library(plotly)
library(xgboost)
tidymodels_prefer()
})
```

```{r}
db <- read.csv("~/Downloads/diabetes.csv")
```

```{r}
vis_miss(db)
```

```{r}
db %>% 
  ggplot(aes(x = Outcome)) + geom_bar() +
  theme_bw()
```

```{r}
db %>% 
  group_by(Outcome) %>% 
  summarise(prop = n()/(dim(db)[1]))
```

```{r}
# Plot the distribution of customer ages using a histogram
ggplot(db, aes(x = Age)) +
  geom_histogram(binwidth = 5, color = "black", fill = "blue") +
  labs(title = "Distribution of Patient Ages", x = "Age", y = "Age")

# Plot the distribution of customer balances using a density plot
ggplot(db, aes(x = BMI)) +
  geom_density(fill = "red", alpha = 0.5) +
  labs(title = "Distribution of BMI", x = "Balance", y = "frequency")

# Plot the distribution of customer credit scores using a box plot
ggplot(db, aes(y = Insulin)) +
  geom_boxplot(color = "black", fill = "green", alpha = 0.5) +
  labs(title = "Distribution of Insulin", y = "Insulin")
```
```{r}
distribution <- function(db, column) {
  min_col <- min(db[[column]])
  max_col <- max(db[[column]])
  
  # Convert the column to numeric
  db[[column]] <- as.numeric(db[[column]])
  
  # Split the data by "Outcome" group
  diabetes_data <- db[db$Outcome == 1, column]
  no_diabetes_data <- db[db$Outcome == 0, column]
  
  # Set up the plot with two side-by-side histograms
  par(mfrow = c(1, 2))
  
  # Histogram for "diabetes == 1"
  hist(diabetes_data, 
       main = paste0("Diabetes Present ", column, " "), 
       xlab = column, 
       ylab = "Frequency",
       col = "red",
       breaks = seq(min_col - 1, max_col + 1, by = 1),
       xlim = c(min_col, max_col),
       ylim = c(0, max(hist(diabetes_data, breaks = seq(min_col - 1, max_col + 1, by = 1), plot = FALSE)$counts)),
       density = 10, 
       angle = 45,
       border = "white")
  
  # Histogram for "no diabetes == 0"
  hist(no_diabetes_data, 
       main = paste0("Diabetes Absent ", column, " "), 
       xlab = column, 
       ylab = "Frequency",
       col = "blue",
       breaks = seq(min_col - 1, max_col + 1, by = 1),
       xlim = c(min_col, max_col),
       ylim = c(0, max(hist(no_diabetes_data, breaks = seq(min_col - 1, max_col + 1, by = 1), plot = FALSE)$counts)),
       density = 10, 
       angle = 45,
       border = "white")
  
  # Reset the layout
  par(mfrow = c(1, 1))
}

# Example usage
distribution(db, "Age")

```

```{r}
#bank_df$Exited_num <- as.numeric(bank_df$Exited) # Convert Exited to numeric variable
diabetes_numeric <- db %>% 
  select_if(is.numeric) # Select only numeric columns
cor_matrix <- cor(diabetes_numeric) # Compute correlation matrix
corrplot(cor_matrix, type = "lower", diag = FALSE) # Plot correlation matrix
```
```{r}
# covert survived and pclass into factors
diabetes_numeric$Outcome <- as.factor(diabetes_numeric$Outcome)
# sort the data frame by survived, so the yes will be on top
db_sort <- db%>% arrange(desc(Outcome))
head(db_sort)
```
##Cross-Validation + Data Splitting
```{r}
set.seed(3435)
db_split <- initial_split(db, prop = 0.80,
                               strata = "Outcome")
db_train <- training(db_split)
db_test <- testing(db_split)
db_fold <- vfold_cv(db_train,v=4)
```

## Recipe
```{r}
# Load libraries
library(recipes)
library(tidymodels)
library(ROSE)

# Assuming df is your data frame or tibble
db$Outcome <- as.factor(db$Outcome)

# Data splitting
set.seed(3435)
db_split <- initial_split(db, prop = 0.80, strata = "Outcome")
db_train <- training(db_split)
db_test <- testing(db_split)
db_fold <- vfold_cv(db_train, v = 6)

# Recipe without step_upsample
db_recipe <- recipe(Outcome ~ ., data = db_train) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_predictors())

# Prepare the recipe
prep(db_recipe)%>% bake(new_data = db_train) %>% 
  group_by(Outcome) %>% 
  summarise(count = n())

```
The step_dummy() function is used to convert all nominal variables into dummy variables. The step_normalize() function is used to scale all variables to have a mean of zero and standard deviation of one. 

The prep() function is then used to prepare the recipe object, and bake() is used to apply the recipe to the training set. Finally, the group_by() and summarise() functions are used to count the number of instances of each value of the Outcome variable in the training set.



#Knn
```{r}
# Define the k-NN model
knn_model <- nearest_neighbor(neighbors = tune()) %>% 
  set_engine("kknn") %>% 
  set_mode("classification")

# Create a workflow with the recipe and model
db_knn_wflow <- workflow() %>% 
  add_recipe(db_recipe) %>%  # Include the recipe
  add_model(knn_model)      # Include the model

# Grid for tuning
neighbors_grid <- grid_regular(neighbors(range = c(1, 10)), levels = 10)

# Tune the model
db_tune_knn <- tune_grid(
  object = db_knn_wflow, 
  resamples = db_fold, 
  grid = neighbors_grid
)

# Select the best model
best_knn_db <- select_best(
  db_tune_knn,
  metric = "roc_auc",
  neighbors
)

```


```{r}
best_knn_wf <- finalize_workflow(db_knn_wflow, best_knn_db)
knn_fit <- fit(best_knn_wf, data = db_train)

# Extract predictions
knn_preds <- augment(knn_fit, new_data = db_train)

# Calculate ROC AUC directly using pROC
roc_curve <- roc(knn_preds$Outcome, knn_preds$.pred_0)
roc_auc_value <- auc(roc_curve)
print(roc_auc_value)

# Confusion Matrix
conf_matrix <- knn_preds %>%
  conf_mat(truth = Outcome, estimate = .pred_class)

# Plot Confusion Matrix
conf_matrix %>% autoplot(type = 'heatmap') +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

```
```{r}
autoplot(db_tune_knn) + theme_minimal()
```
##Logistic Regression

```{r}
# Logistic regression
log_reg <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

db_log_wflow <- workflow() %>% 
  add_model(log_reg) %>% 
  add_recipe(db_recipe)

# Tune the model
db_tune_reg <- tune_grid(
  object = db_log_wflow, 
  resamples = db_fold
)

# Fit the model
log_fit <- fit(db_log_wflow, db_train)

# Extract predictions
log_preds <- augment(log_fit, new_data = db_train)

# Calculate ROC AUC directly using pROC
roc_curve <- roc(log_preds$Outcome, log_preds$.pred_0)
roc_auc_value <- auc(roc_curve)
print(roc_auc_value)

# Confusion Matrix
conf_matrix <- log_preds %>%
  conf_mat(truth = Outcome, estimate = .pred_class)

# Plot Confusion Matrix
conf_matrix %>% autoplot(type = 'heatmap') +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

# Show best tuning parameters
show_best(db_tune_reg, n = 1)

```
### Random Forest 



##Boosted Tree Model
```{r}
bt_class_spec <- boost_tree(mtry = tune(), 
                           trees = tune(), 
                           learn_rate = tune()) %>%
  set_engine("xgboost") %>% 
  set_mode("classification")

bt_class_wf <- workflow() %>% 
  add_model(bt_class_spec) %>% 
  add_recipe(db_recipe)
```

```{r}
bt_grid <- grid_regular(mtry(range = c(1, 6)), 
                        trees(range = c(200, 600)),
                        learn_rate(range = c(-10, -1)),
                        levels = 5)
bt_grid
```

```{r eval=FALSE}
tune_bt_class <- tune_grid(
  bt_class_wf,
  resamples = db_fold,
  grid = bt_grid
)
save(tune_bt_class, file = "tune_bt_class.rda")
```

```{r}
load("tune_bt_class.rda")
autoplot(tune_bt_class) + theme_minimal()
```

```{r}
show_best(tune_bt_class, n = 1)
```

```{r}
best_bt_class <- select_best(tune_bt_class)
```

```{r}
bt_mode_fit <- finalize_workflow(bt_class_wf, best_bt_class)
bt_mode_fit <- fit(bt_mode_fit, db_train)


bt_mode_fit %>% extract_fit_parsnip() %>% 
  vip() +
  theme_minimal()

```

```{r}
library(pROC)

# Assuming bt_mode_fit is the finalized and fitted model
# Replace "Outcome" and ".pred_0" with your actual column names

# Extract predicted probabilities and true outcomes
predictions <- augment(bt_mode_fit, new_data = db_train)
roc_curve <- roc(predictions$Outcome, predictions$.pred_0)

# Calculate AUC
roc_auc_value <- auc(roc_curve)

# Print ROC AUC value
print(roc_auc_value)

# Plot ROC curve
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)

# Add AUC value to the plot
text(0.7, 0.2, paste("AUC =", round(roc_auc_value, 3)), col = "blue", cex = 1.2)

```


##TEST FIT

```{r}
library(pROC)
library(yardstick)

# KNN
knn_predictions <- augment(knn_fit, new_data = db_test)
knn_roc_curve <- roc(knn_predictions$Outcome, knn_predictions$.pred_0)
knn_auc_value <- auc(knn_roc_curve)
# Add AUC value to the plot


# Logistic Regression
log_predictions <- augment(log_fit, new_data = db_test)
log_accuracy <- accuracy(log_predictions, truth = Outcome, estimate = .pred_class)
log_conf_matrix <- conf_mat(log_predictions, truth = Outcome, estimate = .pred_class)

# Boosted Trees
bt_predictions <- augment(bt_mode_fit, new_data = db_test)
bt_roc_curve <- roc(bt_predictions$Outcome, bt_predictions$.pred_0)
bt_auc_value <- auc(bt_roc_curve)
bt_conf_matrix <- conf_mat(bt_predictions, truth = Outcome, estimate = .pred_class)
# Add AUC value to the plot

# Print and plot results
print(paste("KNN AUC:", knn_auc_value))
print("Logistic Regression Accuracy:")
print(log_accuracy)
print("Logistic Regression Confusion Matrix:")
print(log_conf_matrix)
print(paste("Boosted Trees AUC:", bt_auc_value))
print("Boosted Trees Confusion Matrix:")
print(bt_conf_matrix)

# Plot ROC curves
plot(knn_roc_curve, main = "KNN ROC Curve", col = "blue", lwd = 2)
text(0.7, 0.2, paste("AUC =", round(knn_auc_value, 3)), col = "blue", cex = 1.2)
plot(bt_roc_curve, main = "Boosted Trees ROC Curve", col = "green", lwd = 2)
text(0.7, 0.2, paste("AUC =", round(bt_auc_value, 3)), col = "blue", cex = 1.2)

```

### Final Fit

```{r}
library(yardstick)
library(broom)

final_final_fit <- fit(bt_mode_fit, data = db_test)

# Compute ROC AUC
roc_auc_result <- augment(final_final_fit, new_data = db_test) %>%
  roc_auc(truth = Outcome, .pred_0)

# Print ROC AUC
print(roc_auc_result)

# Compute and plot confusion matrix
conf_mat_result <- augment(final_final_fit, new_data = db_test) %>%
  conf_mat(truth = Outcome, .pred_class) %>%
  autoplot(type = 'heatmap')

# Print confusion matrix
print(conf_mat_result)

```



```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}
db_train$Outcome <- factor(db_train$Outcome)
db_recipe_demo <- recipe(Outcome ~ ., data = db_train) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_predictors()) %>% 
  step_upsample(Outcome, over_ratio = 0.5, skip = FALSE)

prep(db_recipe_demo) %>% bake(new_data = db_train) %>% 
  group_by(Outcome) %>% 
  summarise(count = n())
```

```{r}
db_recipe <- recipe(Outcome ~ ., data = db_train ) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_predictors()) %>% 
  step_upsample(Outcome, over_ratio = 1)
```
